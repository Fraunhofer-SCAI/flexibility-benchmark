{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fbc8a9f",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "Generates analysis given logs from a study of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774f102",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, csv, itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to experimental data. Should contain a 'logs' directory.\n",
    "exp_path = \"../../../flexbench-data/3_NSGA-II_varying_goals/3-3_study_epoch_length_gene_length/\"\n",
    "\n",
    "# Target path, in case it is different from the experiment path.\n",
    "# target_path = exp_path\n",
    "target_path = \"../../../flexbench-data/2_baseline_NSGA-II/2-2_tournament/\"\n",
    "\n",
    "# Parameters and values under study.\n",
    "# params = [\"eta_cross\", \"eta_mut\"]\n",
    "# params = [\"pop_size\"]\n",
    "params = [\"gens_epoch\", \"gene_length\"]\n",
    "dict_values = {\n",
    "    # \"eta_cross\": [20, 40, 80, 120, 140, 180],\n",
    "    # \"eta_mut\": [20, 40, 80, 120, 140, 180],\n",
    "    # \"pop_size\": [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    \"gens_epoch\": [5, 10, 15, 20, 25],\n",
    "    \"gene_length\": [2, 3, 5],\n",
    "}\n",
    "params_labels = {\n",
    "    \"eta_cross\": \"Crossover eta\",\n",
    "    \"eta_mut\": \"Mutation eta\",\n",
    "    \"pop_size\": \"Population Size\",\n",
    "    \"gens_epoch\": \"Epoch Length E\",\n",
    "    \"gene_length\": \"Gene Length l\",\n",
    "}\n",
    "\n",
    "# Materials considered as source and target.\n",
    "# materials_source = [\"steel\",\"inconel_718\"]\n",
    "# materials_pairs = [\"steel_to_inconel_718\"]\n",
    "materials_source = [\"steel_and_tungsten_alloy\"]\n",
    "materials_pairs = [\"steel_and_tungsten_alloy_to_inconel_718\"]\n",
    "\n",
    "# Experiment values.\n",
    "repetitions = 50\n",
    "nGens = 50\n",
    "popSize = 100\n",
    "\n",
    "# For calculation of Computational Effort (CE).\n",
    "z = 0.99\n",
    "\n",
    "# False if using population size above.\n",
    "# If one of the paremeters varied is the population size, index of the parameter.\n",
    "popSize_varied = False\n",
    "popSize_idx = 0\n",
    "\n",
    "# True if target was included in parameter study.\n",
    "include_target = False\n",
    "\n",
    "# If True, additionally calculates computational effort and evaluations\n",
    "# based on a percentage of the target hypervolume.\n",
    "include_relaxed_target = True\n",
    "percentage = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c886e",
   "metadata": {},
   "source": [
    "### Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Returns the maximum of each row from 'path'.\"\"\"\n",
    "    print(\"Loading %s...\" % path)\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        data = np.array([max([float(x) for x in row]) for row in reader])\n",
    "    return data[:repetitions]\n",
    "\n",
    "def load_evals_relaxed(path_hypervolume_target, path_hypervolume_current, popSize):\n",
    "    \"\"\"\n",
    "    Return an array with the number of evaluations needed for finding a percentage\n",
    "    of target hypervolumes.\n",
    "    \"\"\" \n",
    "    print(\"Loading %s...\" % path_hypervolume_current)\n",
    "    \n",
    "    with open(path_hypervolume_target, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        hypervolume_target = np.array([max([float(x) for x in row]) for row in reader]) * relaxed_target\n",
    "        hypervolume_target = hypervolume_target[:repetitions]\n",
    "    \n",
    "    with open(path_hypervolume_current, \"r\", newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        data = [[float(x) for x in row] for row in reader]\n",
    "        data = data[:repetitions]\n",
    "    \n",
    "    evals_relaxed = [-1 for _ in range(len(data))]\n",
    "    for idx in range(len(data)):\n",
    "        for gen in range(nGens+1):\n",
    "            if data[idx][gen] >= hypervolume_target[idx]:\n",
    "                evals_relaxed[idx] = (gen+1)*popSize\n",
    "                break\n",
    "    \n",
    "    return np.array(evals_relaxed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642470d",
   "metadata": {},
   "source": [
    "### Computational Effort (CE) calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50533d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_min_effort(evals, nRuns, nGens, popSize, z) :\n",
    "\n",
    "    #Initialize generations vector.\n",
    "    gensVec = [0 for i in range(nGens+1)]\n",
    "    \n",
    "    #Fill generations vector by iterating evaluations vector.\n",
    "    for x in evals :\n",
    "        if x != -1 :\n",
    "            idx = int(x/popSize) - 1\n",
    "            gensVec[idx] = gensVec[idx] + 1\n",
    "    \n",
    "    #Calculate cumulative vector.\n",
    "    for i in range(1,len(gensVec)) :\n",
    "        gensVec[i] = gensVec[i] + gensVec[i-1]\n",
    "    \n",
    "    #Minimum effort initial infinite.\n",
    "    minEff = float('+Inf')\n",
    "    \n",
    "    #For each generation.\n",
    "    for i in range(len(gensVec)) :\n",
    "    \n",
    "        #Calculate probability based on frequencies.\n",
    "        prob = gensVec[i]/float(nRuns)\n",
    "        \n",
    "        if prob == 0:\n",
    "            prob = 1e-7\n",
    "        \n",
    "        #Calculate effort.\n",
    "        if prob == 1.0 :\n",
    "            r = 1.0\n",
    "        else :\n",
    "            r = np.ceil(np.log(1-z)/np.log(1-prob))\n",
    "            \n",
    "        currEff = popSize * (i+1) * r\n",
    "        \n",
    "        #Update minimum effort.\n",
    "        if currEff < minEff :\n",
    "            minEff = currEff\n",
    "\n",
    "            \n",
    "    #Return minimum effort.\n",
    "    return minEff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73aca19",
   "metadata": {},
   "source": [
    "### Load data in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e171851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict():\n",
    "\n",
    "    # Initialize empty dictionary.\n",
    "    data_dict = {}\n",
    "\n",
    "    # For each combination of task and parameter values.\n",
    "    for task in materials_source + materials_pairs:\n",
    "        for values in itertools.product(*[dict_values[key] for key in params]):\n",
    "\n",
    "            # Check if population size is being varied.\n",
    "            global popSize\n",
    "            if popSize_varied:\n",
    "                popSize = values[popSize_idx]\n",
    "\n",
    "            # Key for combination.\n",
    "            pre_key = \"_\".join([\"%s_%d\" % (key, value) for (key, value) in zip(params, values)])\n",
    "            key = pre_key + \"_\" + task\n",
    "\n",
    "            # Load data.\n",
    "            if \"_to_\" in task:\n",
    "                path = load_path + key + \"/adaption/\"\n",
    "                if include_target:\n",
    "                    path_target = load_path + pre_key + \"_\" + task.split(\"_to_\")[-1] + \"/training/\"\n",
    "                else:\n",
    "                    path_target = load_path_target + task.split(\"_to_\")[-1] + \"/training/\"\n",
    "                data_cost = load_evals_relaxed(\n",
    "                    path_target + \"hypervolume.csv\",\n",
    "                    path + \"hypervolume.csv\",\n",
    "                    popSize,\n",
    "                )\n",
    "            else:\n",
    "                path = load_path + key + \"/training/\"\n",
    "                data_cost = load_evals_relaxed(\n",
    "                    path + \"hypervolume.csv\",\n",
    "                    path + \"hypervolume.csv\",\n",
    "                    popSize,\n",
    "                )\n",
    "            data_hypervolume = load_data(path + \"hypervolume.csv\")\n",
    "\n",
    "            # Add data to dictionary.\n",
    "            data_dict[key] = {}\n",
    "            data_dict[key][\"CE\"] = calc_min_effort(data_cost,repetitions,nGens,popSize,z)\n",
    "            data_dict[key][\"hypervolume\"] = np.mean(data_hypervolume)\n",
    "            \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aadd14",
   "metadata": {},
   "source": [
    "### Generate tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75252200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(table, path):\n",
    "    print(\"Saving %s...\" % path)\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f, delimiter=\",\")\n",
    "        writer.writerows(table)\n",
    "\n",
    "def gen_all_tables(data_dict):\n",
    "\n",
    "    # Initialize table for CE and hypervolume.\n",
    "    table = [[\"Task\"] + params + [\"Min. CE\",\"Hypervolume\"]]\n",
    "\n",
    "    # For each combination of task and parameter values.\n",
    "    for task in materials_source + materials_pairs:\n",
    "        for values in itertools.product(*[dict_values[key] for key in params]):\n",
    "\n",
    "            # Initialize new row.\n",
    "            row = [task] + list(values)\n",
    "\n",
    "            # Key for combination.\n",
    "            key = \"_\".join([\"%s_%d\" % (key, value) for (key, value) in zip(params, values)]) + \"_\" + task\n",
    "\n",
    "            # Add values to row.\n",
    "            row.append(data_dict[key][\"CE\"])\n",
    "            row.append(data_dict[key][\"hypervolume\"])\n",
    "\n",
    "            # Add row to table.\n",
    "            table.append(row)\n",
    "    \n",
    "    # Save table for CE and hypervolume.\n",
    "    save_table(table, save_path+\"table_CE_hypervolume.csv\")\n",
    "\n",
    "    # Initialize table for best setups.\n",
    "    table = [[\"Task\",\"Measure\",\"Setup\",\"Min. CE\",\"Hypervolume\"]]\n",
    "\n",
    "    # For each combination of task and measure.\n",
    "    for task in materials_source + materials_pairs:\n",
    "        for measure in [\"CE\", \"hypervolume\"]:\n",
    "\n",
    "            # Initialize row.\n",
    "            row = [task, measure]\n",
    "\n",
    "            # Select keys to consider.\n",
    "            keys = [x for x in data_dict.keys() if x.endswith(task)]\n",
    "\n",
    "            # Find best setup.\n",
    "            if measure == \"CE\":\n",
    "                best_setup = min(keys, key = lambda k: data_dict[k][measure])\n",
    "            elif measure == \"hypervolume\":\n",
    "                best_setup = max(keys, key = lambda k: data_dict[k][measure])\n",
    "\n",
    "            # Extract values.\n",
    "            best_CE = data_dict[best_setup][\"CE\"]\n",
    "            best_hypervolume = data_dict[best_setup][\"hypervolume\"]\n",
    "\n",
    "            # Add setup and values to row.\n",
    "            row.extend([best_setup, best_CE, best_hypervolume])\n",
    "\n",
    "            # Add row to table.\n",
    "            table.append(row)\n",
    "\n",
    "    # Save table for best setups.\n",
    "    save_table(table, save_path+\"table_best_setups.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35fb999",
   "metadata": {},
   "source": [
    "### Generate plots (CE and hypervolume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d35ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plot(measure, measure_label, data_dict):\n",
    "\n",
    "    # Initialize subplots.\n",
    "    ncols = len(materials_source + materials_pairs)\n",
    "    if len(params) == 1:\n",
    "        fig, axsVec = plt.subplots(nrows=1, ncols=ncols, figsize=(16,6), constrained_layout=True)\n",
    "    elif len(params) == 2:\n",
    "        fig, axsVec = plt.subplots(nrows=1, ncols=ncols, figsize=(16,6), subplot_kw={'projection':'3d'}, constrained_layout=True)\n",
    "    else:\n",
    "        print(\"Can't plot for more than 2 parameters at the moment.\")\n",
    "        return\n",
    "    axsVec = [axs for axs in np.array(axsVec).flat]\n",
    "\n",
    "    # For each task.\n",
    "    tasks = materials_source + materials_pairs\n",
    "    for idx in range(len(tasks)):\n",
    "        \n",
    "        # Select task and subplot.\n",
    "        task = tasks[idx]\n",
    "        axs = axsVec[idx]\n",
    "        \n",
    "        # Extract data to be plotted.\n",
    "        data = []\n",
    "        for values in itertools.product(*[dict_values[key] for key in params]):\n",
    "            key = \"_\".join([\"%s_%d\" % (key, value) for (key, value) in zip(params, values)]) + \"_\" + task\n",
    "            data.append(list(values) + [data_dict[key][measure]])\n",
    "        data = np.array(data)\n",
    "                        \n",
    "        # Plot data.\n",
    "        axs.scatter(*[data[:,i] for i in range(len(data[0]))])\n",
    "\n",
    "        # Add subplot title and labels.\n",
    "        fontsize = 16\n",
    "        fontsize_label = 15\n",
    "        axs.set_title(task, fontsize=fontsize, fontweight='bold')\n",
    "        axs.tick_params(axis='x', labelsize=fontsize)\n",
    "        axs.tick_params(axis='y', labelsize=fontsize)\n",
    "        if len(params) == 1:\n",
    "            axs.set_xlabel(params_labels[params[0]], fontsize=fontsize_label, fontweight='bold', labelpad=10)\n",
    "            axs.set_ylabel(measure_label, fontsize=fontsize_label, fontweight='bold', labelpad=15)\n",
    "        elif len(params) == 2:\n",
    "            axs.set_xlabel(params_labels[params[0]], fontsize=fontsize_label, fontweight='bold', labelpad=10)\n",
    "            axs.set_ylabel(params_labels[params[1]], fontsize=fontsize_label, fontweight='bold', labelpad=10)\n",
    "            axs.set_zlabel(measure_label, fontsize=fontsize_label, fontweight='bold', labelpad=15)\n",
    "            axs.tick_params(axis='z', labelsize=fontsize)\n",
    "\n",
    "    # Save plot.\n",
    "    fig.savefig(save_path+\"plots_\"+measure+\".eps\")\n",
    "    print(\"Plot saved in %s.\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834b521",
   "metadata": {},
   "source": [
    "### Run analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca0884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = exp_path + \"logs/\"\n",
    "load_path_target = target_path + \"logs/\"\n",
    "save_path = exp_path + \"analysis/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "relaxed_target = 1.0\n",
    "\n",
    "data_dict = load_dict()\n",
    "gen_all_tables(data_dict)\n",
    "gen_plot(\"CE\", \"CE\", data_dict)\n",
    "gen_plot(\"hypervolume\", \"Hypervolume\", data_dict)\n",
    "\n",
    "if include_relaxed_target:\n",
    "    save_path = exp_path + \"analysis_relaxed_target_%.2f/\" % percentage\n",
    "\n",
    "    try:\n",
    "        os.mkdir(save_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    relaxed_target = percentage\n",
    "\n",
    "    data_dict = load_dict()\n",
    "    gen_all_tables(data_dict)\n",
    "    gen_plot(\"CE\", \"CE\", data_dict)\n",
    "    gen_plot(\"hypervolume\", \"Hypervolume\", data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
